{
 "cells": [
  {
   "cell_type": "raw",
   "id": "28cc8093-3698-4d69-8417-4ca2c8fda7da",
   "metadata": {},
   "source": [
    "Descriptive Statistics - Measures of Central Tendency and variability\n",
    "\n",
    "Perform the following operations on any open source dataset (e.g., data.csv)\n",
    "1. Provide summary statistics (mean, median, minimum, maximum, standard deviation) for\n",
    "a dataset (age, income etc.) with numeric variables grouped by one of the qualitative\n",
    "(categorical) variable. For example, if your categorical variable is age groups and\n",
    "quantitative variable is income, then provide summary statistics of income grouped by the\n",
    "age groups. Create a list that contains a numeric value for each response to the categorical\n",
    "variable.\n",
    "2. Write a Python program to display some basic statistical details like percentile, mean,\n",
    "standard deviation etc. of the species of ‘Iris-setosa’, ‘Iris-versicolor’ and ‘Iris-versicolor’\n",
    "of iris.csv dataset.\n",
    "\n",
    "Provide the codes with outputs and explain everything that you do in this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27f10df1-2f04-462c-816b-755896c265e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (replace 'data.csv' with your dataset file)\n",
    "# For demonstration, we'll create a sample dataset here\n",
    "data = {\n",
    "    'Age': [22, 34, 45, 23, 40, 36, 50, 61, 29, 31],\n",
    "    'Income': [25000, 40000, 50000, 23000, 38000, 42000, 55000, 60000, 37000, 39000],\n",
    "    'Age_Group': ['Youth', 'Adult', 'Adult', 'Youth', 'Adult', 'Adult', 'Senior', 'Senior', 'Youth', 'Adult']\n",
    "}\n",
    "\n",
    "# Convert to a DataFrame\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1113d5f6-cb3e-4bcc-9680-e1ec5a90e612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics Grouped by Age Group:\n",
      "            count          mean          std      min      25%      50%  \\\n",
      "Age_Group                                                                \n",
      "Adult        5.0  41800.000000  4816.637832  38000.0  39000.0  40000.0   \n",
      "Senior       2.0  57500.000000  3535.533906  55000.0  56250.0  57500.0   \n",
      "Youth        3.0  28333.333333  7571.877794  23000.0  24000.0  25000.0   \n",
      "\n",
      "               75%      max  \n",
      "Age_Group                    \n",
      "Adult      42000.0  50000.0  \n",
      "Senior     58750.0  60000.0  \n",
      "Youth      31000.0  37000.0  \n",
      "Summary Statistics for Income and Age Grouped by Age Group:\n",
      "             Age                                                      Income  \\\n",
      "          count       mean       std   min    25%   50%    75%   max  count   \n",
      "Age_Group                                                                     \n",
      "Adult       5.0  37.200000  5.449771  31.0  34.00  36.0  40.00  45.0    5.0   \n",
      "Senior      2.0  55.500000  7.778175  50.0  52.75  55.5  58.25  61.0    2.0   \n",
      "Youth       3.0  24.666667  3.785939  22.0  22.50  23.0  26.00  29.0    3.0   \n",
      "\n",
      "                                                                          \\\n",
      "                   mean          std      min      25%      50%      75%   \n",
      "Age_Group                                                                  \n",
      "Adult      41800.000000  4816.637832  38000.0  39000.0  40000.0  42000.0   \n",
      "Senior     57500.000000  3535.533906  55000.0  56250.0  57500.0  58750.0   \n",
      "Youth      28333.333333  7571.877794  23000.0  24000.0  25000.0  31000.0   \n",
      "\n",
      "                    \n",
      "               max  \n",
      "Age_Group           \n",
      "Adult      50000.0  \n",
      "Senior     60000.0  \n",
      "Youth      37000.0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Group by 'Age_Group' and calculate summary statistics for 'Income'\n",
    "summary_stats = df.groupby('Age_Group')['Income'].describe()\n",
    "print(\"Summary Statistics Grouped by Age Group:\\n\", summary_stats)\n",
    "\n",
    "# Group by 'Age_Group' and calculate summary statistics for both 'Income' and 'Age'\n",
    "# summary_stats = df.groupby('Age_Group')[['Income', 'Age']].describe()\n",
    "summary_stats = df.groupby('Age_Group').describe()\n",
    "print(\"Summary Statistics for Income and Age Grouped by Age Group:\\n\", summary_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cdae691b-c875-455f-894b-f9c177fde50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Income by Age Group:\n",
      " Age_Group\n",
      "Adult     41800.000000\n",
      "Senior    57500.000000\n",
      "Youth     28333.333333\n",
      "Name: Income, dtype: float64\n",
      "\n",
      "Median Income by Age Group:\n",
      " Age_Group\n",
      "Adult     40000.0\n",
      "Senior    57500.0\n",
      "Youth     25000.0\n",
      "Name: Income, dtype: float64\n",
      "\n",
      "Min Income by Age Group:\n",
      " Age_Group\n",
      "Adult     38000\n",
      "Senior    55000\n",
      "Youth     23000\n",
      "Name: Income, dtype: int64\n",
      "\n",
      "Max Income by Age Group:\n",
      " Age_Group\n",
      "Adult     50000\n",
      "Senior    60000\n",
      "Youth     37000\n",
      "Name: Income, dtype: int64\n",
      "\n",
      "Standard Deviation of Income by Age Group:\n",
      " Age_Group\n",
      "Adult     4816.637832\n",
      "Senior    3535.533906\n",
      "Youth     7571.877794\n",
      "Name: Income, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# For individual statistics like mean, median, std, etc.\n",
    "mean_income = df.groupby('Age_Group')['Income'].mean()\n",
    "median_income = df.groupby('Age_Group')['Income'].median()\n",
    "min_income = df.groupby('Age_Group')['Income'].min()\n",
    "max_income = df.groupby('Age_Group')['Income'].max()\n",
    "std_income = df.groupby('Age_Group')['Income'].std()\n",
    "\n",
    "# Print the individual statistics\n",
    "print(\"\\nMean Income by Age Group:\\n\", mean_income)\n",
    "print(\"\\nMedian Income by Age Group:\\n\", median_income)\n",
    "print(\"\\nMin Income by Age Group:\\n\", min_income)\n",
    "print(\"\\nMax Income by Age Group:\\n\", max_income)\n",
    "print(\"\\nStandard Deviation of Income by Age Group:\\n\", std_income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f2099e0-79ce-4721-8217-8ebd5c808274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age_Group\n",
      "Adult     [40000, 50000, 38000, 42000, 39000]\n",
      "Senior                         [55000, 60000]\n",
      "Youth                   [25000, 23000, 37000]\n",
      "Name: Income, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Assuming df is your DataFrame with columns 'Age_Group' (categorical) and 'Income' (numeric)\n",
    "income_by_age = df.groupby('Age_Group')['Income'].apply(list)\n",
    "\n",
    "# Print the grouped income values as lists\n",
    "print(income_by_age)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df3a3709-1d32-474f-8d5c-e447bf3bf114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Preview:\n",
      "   sepal_length  sepal_width  petal_length  petal_width species\n",
      "0           5.1          3.5           1.4          0.2  setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa\n",
      "\n",
      "Statistics for species: setosa\n",
      "Mean:\n",
      "sepal_length    5.006\n",
      "sepal_width     3.418\n",
      "petal_length    1.464\n",
      "petal_width     0.244\n",
      "dtype: float64\n",
      "Standard Deviation:\n",
      "sepal_length    0.352490\n",
      "sepal_width     0.381024\n",
      "petal_length    0.173511\n",
      "petal_width     0.107210\n",
      "dtype: float64\n",
      "Minimum:\n",
      "sepal_length    4.3\n",
      "sepal_width     2.3\n",
      "petal_length    1.0\n",
      "petal_width     0.1\n",
      "dtype: float64\n",
      "Maximum:\n",
      "sepal_length    5.8\n",
      "sepal_width     4.4\n",
      "petal_length    1.9\n",
      "petal_width     0.6\n",
      "dtype: float64\n",
      "Percentiles (25th, 50th, 75th):\n",
      "      sepal_length  sepal_width  petal_length  petal_width\n",
      "0.25           4.8        3.125         1.400          0.2\n",
      "0.50           5.0        3.400         1.500          0.2\n",
      "0.75           5.2        3.675         1.575          0.3\n",
      "\n",
      "Statistics for species: versicolor\n",
      "Mean:\n",
      "sepal_length    5.936\n",
      "sepal_width     2.770\n",
      "petal_length    4.260\n",
      "petal_width     1.326\n",
      "dtype: float64\n",
      "Standard Deviation:\n",
      "sepal_length    0.516171\n",
      "sepal_width     0.313798\n",
      "petal_length    0.469911\n",
      "petal_width     0.197753\n",
      "dtype: float64\n",
      "Minimum:\n",
      "sepal_length    4.9\n",
      "sepal_width     2.0\n",
      "petal_length    3.0\n",
      "petal_width     1.0\n",
      "dtype: float64\n",
      "Maximum:\n",
      "sepal_length    7.0\n",
      "sepal_width     3.4\n",
      "petal_length    5.1\n",
      "petal_width     1.8\n",
      "dtype: float64\n",
      "Percentiles (25th, 50th, 75th):\n",
      "      sepal_length  sepal_width  petal_length  petal_width\n",
      "0.25           5.6        2.525          4.00          1.2\n",
      "0.50           5.9        2.800          4.35          1.3\n",
      "0.75           6.3        3.000          4.60          1.5\n",
      "\n",
      "Statistics for species: virginica\n",
      "Mean:\n",
      "sepal_length    6.588\n",
      "sepal_width     2.974\n",
      "petal_length    5.552\n",
      "petal_width     2.026\n",
      "dtype: float64\n",
      "Standard Deviation:\n",
      "sepal_length    0.635880\n",
      "sepal_width     0.322497\n",
      "petal_length    0.551895\n",
      "petal_width     0.274650\n",
      "dtype: float64\n",
      "Minimum:\n",
      "sepal_length    4.9\n",
      "sepal_width     2.2\n",
      "petal_length    4.5\n",
      "petal_width     1.4\n",
      "dtype: float64\n",
      "Maximum:\n",
      "sepal_length    7.9\n",
      "sepal_width     3.8\n",
      "petal_length    6.9\n",
      "petal_width     2.5\n",
      "dtype: float64\n",
      "Percentiles (25th, 50th, 75th):\n",
      "      sepal_length  sepal_width  petal_length  petal_width\n",
      "0.25         6.225        2.800         5.100          1.8\n",
      "0.50         6.500        3.000         5.550          2.0\n",
      "0.75         6.900        3.175         5.875          2.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Iris dataset\n",
    "df = pd.read_csv('https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/0e7a9b0a5d22642a06d3d5b9bcbad9890c8ee534/iris.csv')\n",
    "\n",
    "# Display the first few rows to understand the dataset\n",
    "print(\"Dataset Preview:\")\n",
    "print(df.head())\n",
    "\n",
    "# 1. Calculate Basic Statistics (mean, std, min, max, percentiles) for each species\n",
    "species_list = ['setosa', 'versicolor', 'virginica']\n",
    "\n",
    "for species in species_list:\n",
    "    print(f\"\\nStatistics for species: {species}\")\n",
    "    species_data = df[df['species'] == species].drop(columns='species')  # Drop the 'species' column for calculation\n",
    "    \n",
    "    # Calculate the basic statistics\n",
    "    mean_values = species_data.mean()\n",
    "    std_values = species_data.std()\n",
    "    min_values = species_data.min()\n",
    "    max_values = species_data.max()\n",
    "    percentiles = species_data.quantile([0.25, 0.5, 0.75])\n",
    "    \n",
    "    # Displaying the statistics\n",
    "    print(f\"Mean:\\n{mean_values}\")\n",
    "    print(f\"Standard Deviation:\\n{std_values}\")\n",
    "    print(f\"Minimum:\\n{min_values}\")\n",
    "    print(f\"Maximum:\\n{max_values}\")\n",
    "    print(f\"Percentiles (25th, 50th, 75th):\\n{percentiles}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cbdb236-7fe5-4939-8a0d-e40537a3aace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sepal_length', 'sepal_width', 'petal_length', 'petal_width',\n",
       "       'species'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "532c73b4-c2e8-4811-ade8-f6a8281f7b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal_length  count    50.000000\n",
      "              mean      5.006000\n",
      "              std       0.352490\n",
      "              min       4.300000\n",
      "              25%       4.800000\n",
      "              50%       5.000000\n",
      "              75%       5.200000\n",
      "              max       5.800000\n",
      "sepal_width   count    50.000000\n",
      "              mean      3.418000\n",
      "              std       0.381024\n",
      "              min       2.300000\n",
      "              25%       3.125000\n",
      "              50%       3.400000\n",
      "              75%       3.675000\n",
      "              max       4.400000\n",
      "petal_length  count    50.000000\n",
      "              mean      1.464000\n",
      "              std       0.173511\n",
      "              min       1.000000\n",
      "              25%       1.400000\n",
      "              50%       1.500000\n",
      "              75%       1.575000\n",
      "              max       1.900000\n",
      "petal_width   count    50.000000\n",
      "              mean      0.244000\n",
      "              std       0.107210\n",
      "              min       0.100000\n",
      "              25%       0.200000\n",
      "              50%       0.200000\n",
      "              75%       0.300000\n",
      "              max       0.600000\n",
      "Name: setosa, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Or directly use this\n",
    "# Group by species and describe all numeric columns\n",
    "summary_stats = df.groupby('species').describe()\n",
    "# print(summary_stats)\n",
    "\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "print(summary_stats)\n",
    "# print(summary_stats.loc['setosa'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ae335064-255d-40a3-86e0-5e03a7fe25cf",
   "metadata": {},
   "source": [
    "The line you referred to in the code:\n",
    "\n",
    "species_data = df[df['species'] == species].drop(columns='species')\n",
    "\n",
    "does two things:\n",
    "\n",
    "1. **Filtering the Data for a Specific Species**:  \n",
    "   `df[df['species'] == species]` filters the original dataset (`df`) to only include the rows where the value in the `species` column matches the current species from the `species_list`.  \n",
    "   For example, when `species` is `'setosa'`, this part of the code selects only the rows where the `species` column has the value `'setosa'`. This results in a subset of the dataframe that contains only data for the specific species.\n",
    "\n",
    "2. **Dropping the `species` Column**:  \n",
    "   `.drop(columns='species')` removes the `species` column from the filtered data.  \n",
    "   Since we're calculating statistics like mean, standard deviation, etc., we only want to include the numerical columns (e.g., `sepal_length`, `sepal_width`, `petal_length`, `petal_width`). The `species` column is categorical and doesn't make sense in the context of these numerical calculations, so it's dropped.\n",
    "\n",
    "### Why it's necessary:\n",
    "\n",
    "- **The Filter**: `df[df['species'] == species]` ensures we work with data specific to each species in the list.\n",
    "- **Dropping `species`**: After filtering for the species, the `species` column is no longer needed for calculating numerical statistics, so we remove it to avoid errors in operations that only apply to numerical columns (like calculating mean, std, etc.).\n",
    "\n",
    "For example, for the species `'setosa'`, the resulting `species_data` will contain only the numerical data for `setosa`, without the `species` column, which will allow the following calculations to be performed only on the numeric features of that species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "831c6bab-ed32-4fcb-a673-ffaad5993625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function confusion_matrix in module sklearn.metrics._classification:\n",
      "\n",
      "confusion_matrix(y_true, y_pred, *, labels=None, sample_weight=None, normalize=None)\n",
      "    Compute confusion matrix to evaluate the accuracy of a classification.\n",
      "\n",
      "    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\n",
      "    is equal to the number of observations known to be in group :math:`i` and\n",
      "    predicted to be in group :math:`j`.\n",
      "\n",
      "    Thus in binary classification, the count of true negatives is\n",
      "    :math:`C_{0,0}`, false negatives is :math:`C_{1,0}`, true positives is\n",
      "    :math:`C_{1,1}` and false positives is :math:`C_{0,1}`.\n",
      "\n",
      "    Read more in the :ref:`User Guide <confusion_matrix>`.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    y_true : array-like of shape (n_samples,)\n",
      "        Ground truth (correct) target values.\n",
      "\n",
      "    y_pred : array-like of shape (n_samples,)\n",
      "        Estimated targets as returned by a classifier.\n",
      "\n",
      "    labels : array-like of shape (n_classes), default=None\n",
      "        List of labels to index the matrix. This may be used to reorder\n",
      "        or select a subset of labels.\n",
      "        If ``None`` is given, those that appear at least once\n",
      "        in ``y_true`` or ``y_pred`` are used in sorted order.\n",
      "\n",
      "    sample_weight : array-like of shape (n_samples,), default=None\n",
      "        Sample weights.\n",
      "\n",
      "        .. versionadded:: 0.18\n",
      "\n",
      "    normalize : {'true', 'pred', 'all'}, default=None\n",
      "        Normalizes confusion matrix over the true (rows), predicted (columns)\n",
      "        conditions or all the population. If None, confusion matrix will not be\n",
      "        normalized.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    C : ndarray of shape (n_classes, n_classes)\n",
      "        Confusion matrix whose i-th row and j-th\n",
      "        column entry indicates the number of\n",
      "        samples with true label being i-th class\n",
      "        and predicted label being j-th class.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    ConfusionMatrixDisplay.from_estimator : Plot the confusion matrix\n",
      "        given an estimator, the data, and the label.\n",
      "    ConfusionMatrixDisplay.from_predictions : Plot the confusion matrix\n",
      "        given the true and predicted labels.\n",
      "    ConfusionMatrixDisplay : Confusion Matrix visualization.\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "    .. [1] `Wikipedia entry for the Confusion matrix\n",
      "           <https://en.wikipedia.org/wiki/Confusion_matrix>`_\n",
      "           (Wikipedia and other references may use a different\n",
      "           convention for axes).\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> from sklearn.metrics import confusion_matrix\n",
      "    >>> y_true = [2, 0, 2, 2, 0, 1]\n",
      "    >>> y_pred = [0, 0, 2, 2, 0, 2]\n",
      "    >>> confusion_matrix(y_true, y_pred)\n",
      "    array([[2, 0, 0],\n",
      "           [0, 0, 1],\n",
      "           [1, 0, 2]])\n",
      "\n",
      "    >>> y_true = [\"cat\", \"ant\", \"cat\", \"cat\", \"ant\", \"bird\"]\n",
      "    >>> y_pred = [\"ant\", \"ant\", \"cat\", \"cat\", \"ant\", \"cat\"]\n",
      "    >>> confusion_matrix(y_true, y_pred, labels=[\"ant\", \"bird\", \"cat\"])\n",
      "    array([[2, 0, 0],\n",
      "           [0, 0, 1],\n",
      "           [1, 0, 2]])\n",
      "\n",
      "    In the binary case, we can extract true positives, etc. as follows:\n",
      "\n",
      "    >>> tn, fp, fn, tp = confusion_matrix([0, 1, 0, 1], [1, 1, 1, 0]).ravel()\n",
      "    >>> (tn, fp, fn, tp)\n",
      "    (0, 2, 1, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# help(confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac39d8e9-8b53-4ac0-9351-0a1b2d5d6216",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
