{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cc7255-4340-4f13-ad71-fea16ea83a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Analytics III\n",
    "# 1. Implement Simple Naïve Bayes classification algorithm using Python/R on iris.csv dataset.\n",
    "# 2. Compute Confusion matrix to find TP, FP, TN, FN, Accuracy, Error rate, Precision, Recall\n",
    "# on the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6ed3c82-7205-4093-ad4b-2a1a98830988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cb65a0a-8d8d-4ee5-a4d2-3897089dbae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "url = \"https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/0e7a9b0a5d22642a06d3d5b9bcbad9890c8ee534/iris.csv\"\n",
    "df= pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99fc6af6-188d-4fa2-b257-29d1adf5afd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Preview:\n",
      "   sepal_length  sepal_width  petal_length  petal_width species\n",
      "0           5.1          3.5           1.4          0.2  setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa\n",
      "\n",
      "Missing values in dataset:\n",
      "sepal_length    0\n",
      "sepal_width     0\n",
      "petal_length    0\n",
      "petal_width     0\n",
      "species         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 3: Display the first few rows of the dataset\n",
    "print(\"Dataset Preview:\")\n",
    "print(df.head())\n",
    "\n",
    "# Step 4: Check for missing values\n",
    "print(\"\\nMissing values in dataset:\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f5789ee-e1ca-4158-b972-92aa26223aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sepal_length', 'sepal_width', 'petal_length', 'petal_width',\n",
       "       'species'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5eaf2860-9015-41b5-bf9d-8fc84cffaac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Split the dataset into features (X) and target (y)\n",
    "X = df.drop('species', axis=1) \n",
    "y = df['species']\n",
    "\n",
    "#OR\n",
    "# X = df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]\n",
    "# y = df['species']\n",
    "\n",
    "\n",
    "# X = df.drop('species', axis=1) \n",
    "# What this line does:\n",
    "# It removes the column named 'species' from the DataFrame df.\n",
    "\n",
    "# The resulting DataFrame contains only the feature columns (i.e., input variables like sepal_length, sepal_width, etc.)\n",
    "\n",
    "# It assigns the result to X, which is the feature matrix used to train the machine learning model.\n",
    "\n",
    "# 🧠 Why we do this:\n",
    "# In supervised learning:\n",
    "\n",
    "# X → input features (the data the model uses to learn)\n",
    "\n",
    "# y → target/output label (what we are trying to predict)\n",
    "\n",
    "# In the Iris dataset:\n",
    "\n",
    "# species is the label (e.g., setosa, versicolor, virginica)\n",
    "\n",
    "# All other columns are numerical features used to classify the species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9becbf4-ab1d-4b72-821a-c39c91f6d7e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width\n",
       "0             5.1          3.5           1.4          0.2\n",
       "1             4.9          3.0           1.4          0.2\n",
       "2             4.7          3.2           1.3          0.2\n",
       "3             4.6          3.1           1.5          0.2\n",
       "4             5.0          3.6           1.4          0.2\n",
       "..            ...          ...           ...          ...\n",
       "145           6.7          3.0           5.2          2.3\n",
       "146           6.3          2.5           5.0          1.9\n",
       "147           6.5          3.0           5.2          2.0\n",
       "148           6.2          3.4           5.4          2.3\n",
       "149           5.9          3.0           5.1          1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3393fb0a-0c23-49bc-8283-582207553a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         setosa\n",
       "1         setosa\n",
       "2         setosa\n",
       "3         setosa\n",
       "4         setosa\n",
       "         ...    \n",
       "145    virginica\n",
       "146    virginica\n",
       "147    virginica\n",
       "148    virginica\n",
       "149    virginica\n",
       "Name: species, Length: 150, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0efc00bc-4f93-4e01-a4b8-368355409ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Split the data into training and testing sets (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9fe3f41-8103-4cec-bfe8-e20830f1b918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GaussianNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.GaussianNB.html\">?<span>Documentation for GaussianNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GaussianNB()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 7: Create and train the Naive Bayes model\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e2742d7-b555-4442-8bcd-c37c09febfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Predict the test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e3977f4-b948-471f-9c44-900b4ea345f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['versicolor', 'setosa', 'virginica', 'versicolor', 'versicolor',\n",
       "       'setosa', 'versicolor', 'virginica', 'versicolor', 'versicolor',\n",
       "       'virginica', 'setosa', 'setosa', 'setosa', 'setosa', 'virginica',\n",
       "       'virginica', 'versicolor', 'versicolor', 'virginica', 'setosa',\n",
       "       'virginica', 'setosa', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'versicolor', 'setosa', 'setosa', 'virginica', 'versicolor',\n",
       "       'setosa', 'setosa', 'setosa', 'virginica', 'versicolor',\n",
       "       'versicolor', 'setosa', 'setosa'], dtype='<U10')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fad00278-af73-43a7-8c89-13be6f78a956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9428571428571428"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c3ff3f6-bedb-4645-a658-860db5df9eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "080bcf42-2147-425d-afe0-34d865ae2cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9533333333333334"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d0812b4-4c81-46ac-877f-42b12ccd3269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19,  0,  0],\n",
       "       [ 0, 12,  1],\n",
       "       [ 0,  0, 13]], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 8: Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f586bdd-d222-42fc-83ce-662d48bdfc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ```\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "# cm = array([[19,  0,  0],\n",
    "#             [ 0, 12,  1],\n",
    "#             [ 0,  0, 13]])\n",
    "# ```\n",
    "\n",
    "# This is a **multi-class confusion matrix** for 3 classes (e.g., *setosa*, *versicolor*, *virginica*). Let's go step-by-step to compute **TP, FP, TN, FN** for each class.\n",
    "\n",
    "# ---\n",
    "\n",
    "# ### ✅ Definitions for a Class (say class *i*):\n",
    "\n",
    "# * **TP (True Positive)**: Correct predictions for class *i* (value at `cm[i][i]`)\n",
    "# * **FP (False Positive)**: Other classes predicted as class *i* (sum of column *i*, excluding `cm[i][i]`)\n",
    "# * **FN (False Negative)**: Class *i* predicted as other classes (sum of row *i*, excluding `cm[i][i]`)\n",
    "# * **TN (True Negative)**: All correct predictions for other classes (everything except row *i* and column *i*)\n",
    "\n",
    "# ---\n",
    "\n",
    "# ### 📌 Let's Calculate for Each Class:\n",
    "\n",
    "# #### 🔹 Class 0 (Setosa):\n",
    "\n",
    "# * TP = `cm[0][0]` = 19\n",
    "# * FP = `cm[1][0] + cm[2][0]` = 0 + 0 = **0**\n",
    "# * FN = `cm[0][1] + cm[0][2]` = 0 + 0 = **0**\n",
    "# * TN = All others = sum of cm except row 0 and column 0:\n",
    "\n",
    "#   ```\n",
    "#   TN = cm[1][1] + cm[1][2] + cm[2][1] + cm[2][2] = 12 + 1 + 0 + 13 = 26\n",
    "#   ```\n",
    "\n",
    "# #### 🔹 Class 1 (Versicolor):\n",
    "\n",
    "# * TP = `cm[1][1]` = 12\n",
    "# * FP = `cm[0][1] + cm[2][1]` = 0 + 0 = **0**\n",
    "# * FN = `cm[1][0] + cm[1][2]` = 0 + 1 = **1**\n",
    "# * TN = sum of cm except row 1 and column 1:\n",
    "\n",
    "#   ```\n",
    "#   TN = cm[0][0] + cm[0][2] + cm[2][0] + cm[2][2] = 19 + 0 + 0 + 13 = 32\n",
    "#   ```\n",
    "\n",
    "# #### 🔹 Class 2 (Virginica):\n",
    "\n",
    "# * TP = `cm[2][2]` = 13\n",
    "# * FP = `cm[0][2] + cm[1][2]` = 0 + 1 = **1**\n",
    "# * FN = `cm[2][0] + cm[2][1]` = 0 + 0 = **0**\n",
    "# * TN = sum of cm except row 2 and column 2:\n",
    "\n",
    "#   ```\n",
    "#   TN = cm[0][0] + cm[0][1] + cm[1][0] + cm[1][1] = 19 + 0 + 0 + 12 = 31\n",
    "#   ```\n",
    "\n",
    "# ---\n",
    "\n",
    "# ### 🔚 Summary Table:\n",
    "\n",
    "# | Class          | TP | FP | FN | TN |\n",
    "# | -------------- | -- | -- | -- | -- |\n",
    "# | Setosa (0)     | 19 | 0  | 0  | 26 |\n",
    "# | Versicolor (1) | 12 | 0  | 1  | 32 |\n",
    "# | Virginica (2)  | 13 | 1  | 0  | 31 |\n",
    "\n",
    "# ---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "50fff71c-675c-4873-b534-674a4f1d6571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class 0 - Setosa:\n",
      "TP = 19 FP = 0 FN = 0 TN = 26\n",
      "\n",
      "Class 1 - Versicolor:\n",
      "TP = 12 FP = 0 FN = 1 TN = 32\n",
      "\n",
      "Class 2 - Virginica:\n",
      "TP = 13 FP = 1 FN = 0 TN = 31\n"
     ]
    }
   ],
   "source": [
    "# For class 0 (setosa)\n",
    "TP0 = cm[0, 0]\n",
    "FP0 = cm[1, 0] + cm[2, 0]\n",
    "FN0 = cm[0, 1] + cm[0, 2]\n",
    "TN0 = cm[1, 1] + cm[1, 2] + cm[2, 1] + cm[2, 2]\n",
    "print(\"\\nClass 0 - Setosa:\")\n",
    "print(\"TP =\", TP0, \"FP =\", FP0, \"FN =\", FN0, \"TN =\", TN0)\n",
    "\n",
    "# For class 1 (versicolor)\n",
    "TP1 = cm[1, 1]\n",
    "FP1 = cm[0, 1] + cm[2, 1]\n",
    "FN1 = cm[1, 0] + cm[1, 2]\n",
    "TN1 = cm[0, 0] + cm[0, 2] + cm[2, 0] + cm[2, 2]\n",
    "print(\"\\nClass 1 - Versicolor:\")\n",
    "print(\"TP =\", TP1, \"FP =\", FP1, \"FN =\", FN1, \"TN =\", TN1)\n",
    "\n",
    "# For class 2 (virginica)\n",
    "TP2 = cm[2, 2]\n",
    "FP2 = cm[0, 2] + cm[1, 2]\n",
    "FN2 = cm[2, 0] + cm[2, 1]\n",
    "TN2 = cm[0, 0] + cm[0, 1] + cm[1, 0] + cm[1, 1]\n",
    "print(\"\\nClass 2 - Virginica:\")\n",
    "print(\"TP =\", TP2, \"FP =\", FP2, \"FN =\", FN2, \"TN =\", TN2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "af19f138-0ba7-427f-aa70-ac0c8f24545d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class 0:\n",
      "TP = 19, FP = 0, FN = 0, TN = 26\n",
      "\n",
      "Class 1:\n",
      "TP = 12, FP = 0, FN = 1, TN = 32\n",
      "\n",
      "Class 2:\n",
      "TP = 13, FP = 1, FN = 0, TN = 31\n"
     ]
    }
   ],
   "source": [
    "#OR use for loop to get values\n",
    "\n",
    "# Number of classes\n",
    "num_classes = cm.shape[0]\n",
    "#cm.shape[0] gives the number of rows in that matrix — which is equal to the number of classes in a multi-class classification task\n",
    "\n",
    "# Initialize lists to store results\n",
    "TP = []\n",
    "FP = []\n",
    "FN = []\n",
    "TN = []\n",
    "\n",
    "# Loop through each class\n",
    "for i in range(num_classes):\n",
    "    tp = cm[i, i]\n",
    "    fp = sum(cm[:, i]) - tp\n",
    "    fn = sum(cm[i, :]) - tp\n",
    "    tn = cm.sum() - (tp + fp + fn)\n",
    "\n",
    "    TP.append(tp)\n",
    "    FP.append(fp)\n",
    "    FN.append(fn)\n",
    "    TN.append(tn)\n",
    "\n",
    "    print(f\"\\nClass {i}:\")\n",
    "    print(f\"TP = {tp}, FP = {fp}, FN = {fn}, TN = {tn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3230cd3b-bbc8-4a8d-9f9c-a32a44fee4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      " [[19  0  0]\n",
      " [ 0 12  1]\n",
      " [ 0  0 13]]\n",
      "\n",
      "Model Evaluation:\n",
      "Accuracy: 0.98\n",
      "Error Rate: 0.02\n",
      "Precision: 0.98\n",
      "Recall: 0.97\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Evaluate the model\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "error_rate = 1 - accuracy\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "#Calculate the metric (e.g., precision, recall, F1) for each class independently, then take the unweighted mean of those scores\n",
    "\n",
    "print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "print(\"\\nModel Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Error Rate: {error_rate:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "79d66706-9b6f-4016-9c3f-a4ab3d8d2135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 10: Visualize the confusion matrix\n",
    "# plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# annot=True\n",
    "# annot is short for annotate.\n",
    "\n",
    "# When set to True, it displays the values (numbers) inside each cell of the heatmap.\n",
    "\n",
    "# If set to False, the heatmap will just show color gradients without any numbers inside the cells.\n",
    "\n",
    "# In your case, with annot=True, the heatmap will show the values from the confusion matrix (TP, FP, FN, TN) inside each grid cell.\n",
    "\n",
    "# cmap='Blues'\n",
    "# cmap refers to the color map (or color scheme) used to represent the values.\n",
    "\n",
    "# 'Blues' is a built-in color scheme that uses different shades of blue. Lighter shades represent lower values, while darker shades represent higher values.\n",
    "\n",
    "# You can also use other color schemes, such as 'viridis', 'coolwarm', etc., depending on the visual style you're going for.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8c99eb08-8fcf-4c7f-9a45-4826ee6acc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Naïve Bayes Overview:\n",
    "\n",
    "# **Naïve Bayes** is a **simple probabilistic classification algorithm** based on **Bayes' Theorem** with an assumption of **conditional independence** between the features. It’s widely used for classification tasks, especially when the data set is large.\n",
    "\n",
    "# ### Bayes’ Theorem:\n",
    "\n",
    "# Bayes' Theorem describes the probability of a class $C$ given the data $X$ (features):\n",
    "\n",
    "# $$\n",
    "# P(C | X) = \\frac{P(X | C) \\cdot P(C)}{P(X)}\n",
    "# $$\n",
    "\n",
    "# Where:\n",
    "\n",
    "# * $P(C | X)$ is the **posterior probability** (probability of class $C$ given the data $X$).\n",
    "# * $P(X | C)$ is the **likelihood** (probability of the data $X$ given the class $C$).\n",
    "# * $P(C)$ is the **prior probability** of class $C$.\n",
    "# * $P(X)$ is the **evidence** or the total probability of data $X$.\n",
    "\n",
    "# #### Naïve Assumption:\n",
    "\n",
    "# * Features (attributes) are **conditionally independent** given the class label. This simplifies the model significantly because the joint probability $P(X | C)$ can be decomposed into a product of individual feature probabilities:\n",
    "\n",
    "#   $$\n",
    "#   P(X | C) = P(x_1 | C) \\cdot P(x_2 | C) \\cdot ... \\cdot P(x_n | C)\n",
    "#   $$\n",
    "\n",
    "# ---\n",
    "\n",
    "# ### Why is it called **\"Naïve\"**?\n",
    "\n",
    "# The model makes the **\"naïve\" assumption** that all features are **independent**, which is rarely the case in real-world data. However, this simplification often works surprisingly well, especially in tasks like **spam classification**, **text classification**, and **sentiment analysis**.\n",
    "\n",
    "# ---\n",
    "\n",
    "# ### What We Did in Naïve Bayes for the Iris Dataset:\n",
    "\n",
    "# Let’s break down the steps we followed:\n",
    "\n",
    "# 1. **Loaded the Data**:\n",
    "\n",
    "#    * We used the **Iris dataset** (`iris.csv`), which contains features like **sepal length**, **sepal width**, **petal length**, and **petal width**. The target (class) variable is the **species** of the flower.\n",
    "\n",
    "# 2. **Preprocessing**:\n",
    "\n",
    "#    * We split the data into **training** and **testing** sets to evaluate the model's performance.\n",
    "#    * We separated the features (`X`) and the target labels (`y`).\n",
    "\n",
    "# 3. **Naïve Bayes Model**:\n",
    "\n",
    "#    * We **imported and used** the `GaussianNB()` classifier from **scikit-learn**, which is a variant of Naïve Bayes suited for continuous data that follows a **Gaussian (normal) distribution**.\n",
    "\n",
    "# 4. **Model Training**:\n",
    "\n",
    "#    * We **trained** the model on the training data using the `fit()` method, which estimates the parameters of the model (i.e., means and variances of each feature for each class).\n",
    "\n",
    "# 5. **Prediction**:\n",
    "\n",
    "#    * We used the trained model to **predict the species** for the test data using the `predict()` method.\n",
    "\n",
    "# 6. **Evaluation**:\n",
    "\n",
    "#    * We **computed a confusion matrix** to evaluate the performance of the model on the test data. The confusion matrix helps us understand the **true positives**, **false positives**, **true negatives**, and **false negatives**.\n",
    "\n",
    "# 7. **Visualized**:\n",
    "\n",
    "#    * We plotted the **confusion matrix** as a heatmap to easily visualize how well the model predicted each class (species).\n",
    "\n",
    "# ---\n",
    "\n",
    "# ### **Why Naïve Bayes Works Well for this Task:**\n",
    "\n",
    "# * **Feature Independence Assumption**: Although real-world features (like sepal/petal lengths) are likely correlated, Naïve Bayes works well in practice even when the independence assumption is violated. It performs well with relatively simple datasets like Iris.\n",
    "\n",
    "# * **Efficiency**: Naïve Bayes is **computationally efficient** and works well even with a small dataset. It is particularly effective when the number of features is large.\n",
    "\n",
    "# ---\n",
    "\n",
    "# ### Summary of Steps in the Code:\n",
    "\n",
    "# 1. **Load the dataset** and check for missing values.\n",
    "# 2. **Split** the dataset into **training** and **testing** sets.\n",
    "# 3. **Train** a **Naïve Bayes classifier** (`GaussianNB`).\n",
    "# 4. **Make predictions** on the test set.\n",
    "# 5. **Evaluate** the model using a **confusion matrix**.\n",
    "# 6. **Visualize** the confusion matrix with **heatmap**.\n",
    "\n",
    "# ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f374c34c-a01c-410a-a76b-0b4272db79b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Naïve Bayes, the key assumption is that **all the features (or attributes) used to predict the class are independent** of each other **given the class label**. This is referred to as the **\"naïve\" assumption**.\n",
    "\n",
    "# ### 🧠 What Does \"Independent\" Mean in This Context?\n",
    "\n",
    "# When we say that features are **independent**, we mean that the presence (or value) of one feature does not affect the presence (or value) of another feature within the same class. In simpler terms:\n",
    "\n",
    "# * **Feature 1 (e.g., petal length)** does not depend on **Feature 2 (e.g., petal width)** for a particular class of flowers (e.g., Iris-setosa).\n",
    "# * In Naïve Bayes, we assume that knowing the value of one feature doesn't provide any additional information about the others when we already know the class.\n",
    "\n",
    "# ### Example with Iris Dataset:\n",
    "\n",
    "# In the **Iris dataset**, the features are:\n",
    "\n",
    "# * **Sepal length**\n",
    "# * **Sepal width**\n",
    "# * **Petal length**\n",
    "# * **Petal width**\n",
    "\n",
    "# Let’s say we are trying to predict the species (class) of the flower based on these features.\n",
    "\n",
    "# * **Naïve Assumption**: We assume that:\n",
    "\n",
    "#   * **Sepal length** is independent of **Sepal width**, **Petal length**, and **Petal width**, given the class.\n",
    "#   * **Petal length** is independent of **Sepal length**, **Sepal width**, and **Petal width**, given the class.\n",
    "#   * And so on.\n",
    "\n",
    "# So, if we are classifying a flower as **Iris-setosa**, the model assumes that the features (sepal length, sepal width, petal length, petal width) are independent of each other for that class.\n",
    "\n",
    "# ---\n",
    "\n",
    "# ### 🎯 Why \"Naïve\"?\n",
    "\n",
    "# The assumption is called **\"naïve\"** because, in reality, the features in most datasets are often **correlated**. For example:\n",
    "\n",
    "# * In the Iris dataset, **petal length** and **petal width** are likely correlated (they both tend to grow larger for a particular species).\n",
    "# * Similarly, **sepal length** and **sepal width** might be related in certain species.\n",
    "\n",
    "# But, despite this, the Naïve Bayes algorithm works well in many cases, even when the assumption of independence is **not fully accurate**. This is why it is often used for text classification and other problems where the features might not be strongly correlated.\n",
    "\n",
    "# ---\n",
    "\n",
    "# ### 🔄 How Does This Work in the Model?\n",
    "\n",
    "# In the **Naïve Bayes classifier**, for each class $C$, the model calculates the **likelihood** of the data point (the feature values) given the class:\n",
    "\n",
    "# $$\n",
    "# P(X | C) = P(x_1 | C) \\cdot P(x_2 | C) \\cdot ... \\cdot P(x_n | C)\n",
    "# $$\n",
    "\n",
    "# Where:\n",
    "\n",
    "# * $X = (x_1, x_2, ..., x_n)$ represents the features (e.g., sepal length, sepal width, etc.).\n",
    "# * $P(x_i | C)$ is the probability of each feature $x_i$ given the class $C$.\n",
    "\n",
    "# Because of the **independence assumption**, the likelihood $P(X | C)$ is simply the product of the individual probabilities of each feature given the class.\n",
    "\n",
    "# ---\n",
    "\n",
    "# ### 🏁 To Summarize:\n",
    "\n",
    "# * **Naïve Bayes assumes that all features are independent** given the class label.\n",
    "# * This makes the model simple and efficient, but it might not always be true in real-world data.\n",
    "# * Despite this **naïve** assumption, the algorithm works well in practice in many cases.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149bdbee-74e7-4770-9aec-a9821afbea35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the Naïve Bayes classification example with the Iris dataset, here are the key things that were calculated:\n",
    "\n",
    "# ### 1. **Class Probabilities (Prior Probabilities)**:\n",
    "\n",
    "# * These represent the probability of each class (species) in the dataset, independent of the features.\n",
    "# * For example, if we have three species in the dataset (setosa, versicolor, virginica), the prior probability for each class is calculated as:\n",
    "\n",
    "#   $$\n",
    "#   P(C) = \\frac{\\text{Number of samples in class C}}{\\text{Total number of samples}}\n",
    "#   $$\n",
    "# * So, if there are 50 samples of setosa, 50 of versicolor, and 50 of virginica, the prior probability for each class would be 1/3.\n",
    "\n",
    "# ### 2. **Likelihoods (Conditional Probabilities)**:\n",
    "\n",
    "# * These are the probabilities of each feature given the class.\n",
    "# * For example, for the **setosa** class, we calculate the likelihood of having a particular sepal length, sepal width, petal length, and petal width.\n",
    "# * In **Gaussian Naïve Bayes**, this is typically done by assuming that the features follow a normal (Gaussian) distribution for each class. The likelihood of a feature value is computed using the **mean** and **variance** for each feature in each class:\n",
    "\n",
    "#   $$\n",
    "#   P(x_i | C) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} e^{-\\frac{(x_i - \\mu)^2}{2 \\sigma^2}}\n",
    "#   $$\n",
    "\n",
    "#   where:\n",
    "\n",
    "#   * $\\mu$ is the mean of the feature for class $C$,\n",
    "#   * $\\sigma$ is the standard deviation of the feature for class $C$,\n",
    "#   * $x_i$ is the feature value for the data point being classified.\n",
    "\n",
    "# ### 3. **Posterior Probabilities**:\n",
    "\n",
    "# * After calculating the prior probabilities and likelihoods, we compute the **posterior probability** for each class given the features:\n",
    "\n",
    "#   $$\n",
    "#   P(C | X) \\propto P(C) \\cdot P(x_1 | C) \\cdot P(x_2 | C) \\cdot \\dots \\cdot P(x_n | C)\n",
    "#   $$\n",
    "\n",
    "#   where:\n",
    "\n",
    "#   * $P(C | X)$ is the probability of class $C$ given the data $X$,\n",
    "#   * $P(C)$ is the prior probability of class $C$,\n",
    "#   * $P(x_i | C)$ is the likelihood of feature $x_i$ given class $C$.\n",
    "\n",
    "# * We repeat this calculation for each class (e.g., setosa, versicolor, virginica), and the class with the **highest posterior probability** is chosen as the predicted class for the input data.\n",
    "\n",
    "# ### 4. **Predictions**:\n",
    "\n",
    "# * Once the model is trained, it can predict the class for each instance in the test set by choosing the class with the highest posterior probability.\n",
    "\n",
    "# ### 5. **Confusion Matrix**:\n",
    "\n",
    "# * After making predictions on the test set, we evaluated the performance of the model using the **confusion matrix**.\n",
    "# * The confusion matrix shows how many instances were correctly or incorrectly classified for each class:\n",
    "\n",
    "#   * **True Positives (TP)**: Correctly predicted instances for a given class.\n",
    "#   * **False Positives (FP)**: Instances of other classes incorrectly predicted as the current class.\n",
    "#   * **True Negatives (TN)**: Instances of other classes correctly predicted as not the current class.\n",
    "#   * **False Negatives (FN)**: Instances of the current class incorrectly predicted as another class.\n",
    "\n",
    "# ### 6. **Performance Metrics**:\n",
    "\n",
    "# * From the confusion matrix, we can calculate various performance metrics like:\n",
    "\n",
    "#   * **Accuracy**: The proportion of correctly predicted instances out of all instances.\n",
    "#   * **Precision**: The proportion of correctly predicted positive instances among all predicted positives.\n",
    "#   * **Recall**: The proportion of correctly predicted positive instances among all actual positives.\n",
    "#   * **F1-Score**: The harmonic mean of precision and recall, useful when we need a balance between the two.\n",
    "\n",
    "# ### Summary of What Was Calculated:\n",
    "\n",
    "# 1. **Prior Probabilities**: The initial probability of each class.\n",
    "# 2. **Likelihoods**: The probability of each feature given the class, assuming Gaussian distribution.\n",
    "# 3. **Posterior Probabilities**: The final probability of each class given the features.\n",
    "# 4. **Predictions**: Class predictions for the test data based on the highest posterior probability.\n",
    "# 5. **Confusion Matrix**: A matrix showing the true vs predicted class counts.\n",
    "# 6. **Performance Metrics**: Accuracy, precision, recall, etc., derived from the confusion matrix.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
